# WR API Suite

The WR API Suite monorepo houses the first production-ready pipeline for WeRobots: generating rich question sets from free-form briefs and applying them to large batches of documents. The backend streams generation and grading progress over Server-Sent Events (SSE), records token usage for each organization, and exposes tenant-level billing controls. The Next.js frontend offers operator tooling for designing question sets, uploading transcripts or snippets, reviewing answers, and managing credentials.

## Identity store bootstrap

- The local identity store now starts empty. When you load the operator console for the first time,
  the app prompts you to create a master organization and owner. Master owners can view
  platform-wide metrics and manage which organizations are treated as "master" tenants.
- User accounts and organizations are provisioned inside Keycloak. The backend mirrors the
  identifiers generated by Keycloak so local billing metadata continues to work as before.
- Override the on-disk location of the identity store by setting `IDENTITY_FILE_PATH`. This is
  useful for tests or alternate deployments that want to isolate identity data from the default
  `data/identity.json` file at the repository root.

### Keycloak integration

- `dev.sh` exports the Keycloak configuration expected by the Docker Compose stack. On the first
  signup the backend will automatically create the realm, client, default roles, organization group,
  and owner account.
- All login, signup, and bootstrap flows now authenticate against Keycloak. The backend exchanges
  the credentials for a Keycloak access token and reuses it for subsequent API requests.
- To point at a different Keycloak instance set the following variables (see `backend/.env.sample`):
  `KEYCLOAK_BASE_URL`, `KEYCLOAK_REALM`, `KEYCLOAK_CLIENT_ID`, `KEYCLOAK_CLIENT_SECRET`,
  `KEYCLOAK_ADMIN_USERNAME`, and `KEYCLOAK_ADMIN_PASSWORD`.
- Automated tests expect these values to resolve to a reachable Keycloak realm. When running the
  suite locally outside `dev.sh`, export the variables above so the backend can fetch JWKS and issue
  password grants against your instance.

## Local infrastructure

Local development depends on Docker to emulate AWS DynamoDB and Keycloak. The `dev.sh` helper spins
up both services alongside the frontend and backend development servers.

```bash
./dev.sh
```

The script launches the services defined in `docker-compose.dev.yml` and tears them down when the
frontend/backend processes stop. The Compose stack exposes the following ports on the host:

- DynamoDB Local: http://localhost:8000
- Keycloak: http://localhost:8080 (admin username/password: `admin` / `admin`)

All runtime data lives under the repository's `data/` directory:

- `data/keycloak/` stores the embedded database for the development Keycloak container.
- `data/dynamodb/` holds the DynamoDB Local file store.
- `data/cache/` contains optional OpenAI response caches when `CACHE_DIR` is left unset.

To reset both services to a clean slate, stop any running dev stack and wipe the
local state with:

```bash
npm run reset-local
```

The script tears down the Docker Compose services if Docker is available and
removes the `data/keycloak/`, `data/dynamodb/`, and `data/identity.json`
artifacts so the next `./dev.sh` run starts from an empty environment.

Remove or rename the folders above manually if you prefer finer-grained
cleanup.

You can manage the containers independently with the Docker CLI if needed, for example:

```bash
docker compose -f docker-compose.dev.yml up -d
# ...
docker compose -f docker-compose.dev.yml down --remove-orphans
```

When deploying to staging or production, replace these containers with the managed AWS DynamoDB
service and the dedicated Keycloak instances provisioned for each environment.
